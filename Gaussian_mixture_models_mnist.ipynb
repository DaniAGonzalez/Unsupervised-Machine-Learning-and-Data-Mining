{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import multivariate_normal"
      ],
      "metadata": {
        "id": "FJkuy--utCks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multivariate_normal_pdf(x, mean, cov):\n",
        "    \"\"\"\n",
        "    Compute the probability density function of a multivariate normal distribution.\n",
        "\n",
        "    Parameters:\n",
        "        x (ndarray): Data points of shape (n, d), where n is the number of points and d is the dimension.\n",
        "        mean (ndarray): Mean vector of shape (d,).\n",
        "        cov (ndarray): Covariance matrix of shape (d, d).\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Probability density function evaluated at each data point.\n",
        "    \"\"\"\n",
        "    d = mean.shape[0]  # Dimension of the space\n",
        "    cov_det = np.linalg.det(cov)  # Determinant of the covariance matrix\n",
        "    cov_inv = np.linalg.inv(cov)  # Inverse of the covariance matrix\n",
        "    norm_const = 1.0 / ((2 * np.pi) ** (d / 2) * cov_det ** 0.5)  # Normalization constant\n",
        "\n",
        "    diff = x - mean  # Difference between x and the mean\n",
        "    exponent = -0.5 * np.sum(diff @ cov_inv * diff, axis=1)  # Exponent calculation\n",
        "\n",
        "    return norm_const * np.exp(exponent)  # Final PDF"
      ],
      "metadata": {
        "id": "gE0DMt_6nXAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFHVC5yrsl_D"
      },
      "outputs": [],
      "source": [
        "# Class GMM\n",
        "class GMM:\n",
        "  \"\"\"constructor method with parameters of k (numbers of gaussians),\n",
        "  data_dim is the number of dimensiones (2 if x,y),\n",
        "  max_iter is the max number of iterations.\"\"\"\n",
        "  def __init__(self,k,data_dim,max_iter,tol):\n",
        "    self.k = k\n",
        "    self.data_dim = data_dim\n",
        "    self.max_iter = max_iter\n",
        "    self.tol = tol\n",
        "\n",
        "  def init_parameters(self,data):\n",
        "    n = data.shape [0] #all data retrieving from the rows\n",
        "    self.mu = np.random.rand(self.k, self.data_dim) * np.max(data, axis=0) #init random mu\n",
        "    self.cov = [np.eye(self.data_dim) for _ in range(self.k)] #init cov matrix\n",
        "    self.w = np.ones(self.k)/self.k #sames\n",
        "\n",
        "\n",
        "  def e_step(self,data):\n",
        "    \"\"\"computes the conditionals probabilities that the x_i value belongs\n",
        "    to the cluster k given the actual models parameters > responsabilitites\"\"\"\n",
        "    n = data.shape[0]\n",
        "    responsab = np.zeros((n, self.k)) #responsab matrix initilization\n",
        "\n",
        "    for i in range(self.k):\n",
        "      responsab[:, i] = self.w[i] * multivariate_normal_pdf(data, mean=self.mu[i], cov=self.cov[i])\n",
        "\n",
        "    responsab /= np.sum(responsab, axis=1, keepdims=True)  # Normalizat to sum 1\n",
        "    return responsab\n",
        "\n",
        "\n",
        "  def m_step(self, data, responsab):\n",
        "    \"\"\"using the data and the responsab computed in the e-step\n",
        "    updates the model parameters theta\"\"\"\n",
        "    sum_cluster = np.sum(responsab, axis=0) #suming responsab per cluster\n",
        "\n",
        "\n",
        "    self.w = sum_cluster / np.sum(sum_cluster) #new weights\n",
        "\n",
        "    self.mu = np.dot(responsab.T, data) / sum_cluster[:, np.newaxis] #new mu\n",
        "\n",
        "    self.cov = []\n",
        "    for j in range(self.k): #for each gaussiana\n",
        "      difference = data - self.mu[j] #computation of the \"difference\" wich is the data - mean\n",
        "      cov_matrix = np.dot(responsab[:, j] * difference.T, difference) / sum_cluster[j]\n",
        "      #responsability shape (N,K), difference shape (N,K)\n",
        "      self.cov.append(cov_matrix)\n",
        "\n",
        "  def log_likelihood(self, data):\n",
        "        \"\"\"computation of total log likelihood\"\"\"\n",
        "        log_likelihood = 0\n",
        "        for j in range(self.k):\n",
        "            log_likelihood += np.sum(self.w[j] * multivariate_normal_pdf(data, mean=self.mu[j], cov=self.cov[j]))\n",
        "        return np.log(log_likelihood)\n",
        "\n",
        "\n",
        "  def fit(self, data):\n",
        "        \"\"\"applying EM\"\"\"\n",
        "        self.init_parameters(data)\n",
        "        log_likelihoods = []\n",
        "\n",
        "        for iteration in range(self.max_iter):\n",
        "            r = self.e_step(data)  # E-step\n",
        "            self.m_step(data, r)  # M-step\n",
        "            log_likelihood = self.log_likelihood(data)\n",
        "            log_likelihoods.append(log_likelihood)\n",
        "\n",
        "            if iteration > 0 and abs(log_likelihoods[-1] - log_likelihoods[-2]) < self.tol:\n",
        "                print(f\"convergency {iteration}\")\n",
        "                break\n",
        "\n",
        "        return log_likelihoods\n",
        "\n",
        "  def predict(self, data):\n",
        "      \"\"\"assigning points to the closest clusters\"\"\"\n",
        "      responsab = self.e_step(data)\n",
        "      return np.argmax(responsab, axis=1)\n",
        "\n",
        "  def get_params(self):\n",
        "      \"\"\"returning theta\"\"\"\n",
        "      return self.w, self.mu, self.cov\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2dim data\n",
        "data_2d = pd.read_csv('2gaussian.txt', header=None, delim_whitespace=True).values\n",
        "\n",
        "# instantiation of the model\n",
        "gmm_2d = GMM(k=2, data_dim=2, max_iter=100, tol=1e-4)\n",
        "log_likelihoods_2d = gmm_2d.fit(data_2d)\n",
        "\n",
        "w_2d, mu_2d, cov_2d = gmm_2d.get_params()\n",
        "\n",
        "print(\"Weights:\", w_2d)\n",
        "print(\"Mean:\", mu_2d)\n",
        "print(\"Cov:\", cov_2d)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGjO9GGB6NZ7",
        "outputId": "e85bcea6-7d64-4f2b-be53-b925b2221e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "convergency 14\n",
            "Weights: [0.66466015 0.33533985]\n",
            "Mean: [[7.01481251 3.98408503]\n",
            " [2.99735405 3.05172257]]\n",
            "Cov: [array([[0.97187054, 0.49583164],\n",
            "       [0.49583164, 0.99975505]]), array([[1.01557908, 0.0266261 ],\n",
            "       [0.0266261 , 2.93532613]])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-f3226c5096dc>:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  data_2d = pd.read_csv('2gaussian.txt', header=None, delim_whitespace=True).values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3dim data\n",
        "dim3_data = pd.read_csv('3gaussian.txt', header=None, delim_whitespace=True).values\n",
        "\n",
        "# instantiation of the model\n",
        "gmm_3d = GMM(k=3, data_dim=2, max_iter=100, tol=1e-4)\n",
        "log_likelihoods_3d = gmm_3d.fit(dim3_data)\n",
        "\n",
        "w_3d, mu_3d, cov_3d = gmm_3d.get_params()\n",
        "\n",
        "print(\"Weights:\", w_3d)\n",
        "print(\"Mean:\", mu_3d)\n",
        "print(\"Cov:\", cov_3d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WElMeLf591GZ",
        "outputId": "e3ff6a4c-3ea2-40ea-bcf4-a291cdc092ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-aa3d7693c949>:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dim3_data = pd.read_csv('3gaussian.txt', header=None, delim_whitespace=True).values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "convergency 78\n",
            "Weights: [0.29548617 0.22098842 0.48352542]\n",
            "Mean: [[7.04168934 4.0254312 ]\n",
            " [3.12078453 3.2167729 ]\n",
            " [5.03740251 7.02608048]]\n",
            "Cov: [array([[0.9577765 , 0.48713354],\n",
            "       [0.48713354, 0.98980409]]), array([[1.10953378, 0.1651689 ],\n",
            "       [0.1651689 , 3.71079462]]), array([[0.95481118, 0.16824403],\n",
            "       [0.16824403, 0.9403016 ]])]\n"
          ]
        }
      ]
    }
  ]
}