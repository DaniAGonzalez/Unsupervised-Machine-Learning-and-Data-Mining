{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## **Parsing**\n"
   ],
   "metadata": {
    "id": "aQeXxZyNNlZN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pe5yQWMuPRQI",
    "outputId": "7ce096fd-5743-41e3-d239-515e6672c75b",
    "ExecuteTime": {
     "end_time": "2025-01-15T17:08:41.579629Z",
     "start_time": "2025-01-15T17:08:41.534597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "# Training images\n",
    "with open('train-images.idx3-ubyte', 'rb') as i:\n",
    "    magic, size = struct.unpack('>II', i.read(8))  #reading header\n",
    "    i.seek(16)  \n",
    "    data_1 = np.fromfile(i, dtype=np.uint8)  \n",
    "\n",
    "# Retrieving the dataset \n",
    "training_images = data_1.reshape(-1, 784)  # the -1 value reshape the array indicating the unknown numer of rows and 784 columns \n",
    "print(training_images.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Training labels\n",
    "with open ('train-labels.idx1-ubyte', 'rb') as g:\n",
    "  magic, size, = struct.unpack('>II', g.read(8))\n",
    "  g.seek(8)\n",
    "  data_2 = np.fromfile(g, dtype=np.dtype(np.uint8))\n",
    "\n",
    "training_labels = data_2.reshape(-1, 1)\n",
    "\n",
    "print(training_labels.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEr1phI3KIBZ",
    "outputId": "b7ea95d7-9cba-4ad2-ab4c-e61eb1532ec7",
    "ExecuteTime": {
     "end_time": "2025-01-15T17:08:43.594496Z",
     "start_time": "2025-01-15T17:08:43.589912Z"
    }
   },
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test data\n",
    "with open('t10k-images.idx3-ubyte', 'rb') as h:\n",
    "    magic, size = struct.unpack('>II', h.read(8))\n",
    "    h.seek(16)\n",
    "    data_3 = np.fromfile(h, dtype=np.dtype(np.uint8))\n",
    "\n",
    "test_images = data_3.reshape(-1, 784)\n",
    "\n",
    "print(test_images.shape)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIlazSD1Mnjv",
    "outputId": "0aebaf6a-aa15-4fc6-cd40-1b8004376bc5",
    "ExecuteTime": {
     "end_time": "2025-01-15T17:08:45.487083Z",
     "start_time": "2025-01-15T17:08:45.481446Z"
    }
   },
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test Labels\n",
    "with open ('t10k-labels.idx1-ubyte', 'rb') as j:\n",
    "  magic, size, = struct.unpack('>II', j.read(8))\n",
    "  j.seek(8)\n",
    "  data_4 = np.fromfile(j, dtype=np.dtype(np.uint8))\n",
    "\n",
    "test_labels = data_4.reshape(-1, 1)\n",
    "\n",
    "print(test_labels.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5T8kGt4M7hK",
    "outputId": "b06b938c-a703-4125-fa15-a9a121441852",
    "ExecuteTime": {
     "end_time": "2025-01-15T17:08:47.271304Z",
     "start_time": "2025-01-15T17:08:47.266887Z"
    }
   },
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Normalization**"
   ],
   "metadata": {
    "id": "JLYWabADNpU9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(training_images.min())\n",
    "print(training_images.max())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "thm9tCjvNwjQ",
    "outputId": "c1939111-ab1d-4e90-9557-d038cdfa66aa",
    "ExecuteTime": {
     "end_time": "2025-01-15T17:08:52.945166Z",
     "start_time": "2025-01-15T17:08:52.921693Z"
    }
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "255\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(training_images[1:5])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "HOr8u5ldOLQ-",
    "outputId": "07db770d-4029-4a15-caa5-a48e23e9c212",
    "ExecuteTime": {
     "end_time": "2025-01-15T17:08:54.753640Z",
     "start_time": "2025-01-15T17:08:54.750445Z"
    }
   },
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print(test_images.min())\n",
    "print(test_images.max())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:08:57.108953Z",
     "start_time": "2025-01-15T17:08:57.103554Z"
    }
   },
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Normalizing training images\n",
    "training_images = training_images/255\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:08:57.971433Z",
     "start_time": "2025-01-15T17:08:57.900716Z"
    }
   },
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Normalizing test images\n",
    "test_images = test_images/255"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:09:00.733982Z",
     "start_time": "2025-01-15T17:09:00.716995Z"
    }
   },
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215686\n",
      " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
      " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1372549  0.94509804\n",
      " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      " 0.58823529 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.58039216\n",
      " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058824\n",
      " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
      " 0.31372549 0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333333 0.99215686\n",
      " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.32941176 0.7254902\n",
      " 0.62352941 0.59215686 0.23529412 0.14117647 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.87058824 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.94509804 0.77647059 0.77647059 0.77647059 0.77647059\n",
      " 0.77647059 0.77647059 0.77647059 0.77647059 0.66666667 0.20392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2627451  0.44705882 0.28235294 0.44705882 0.63921569 0.89019608\n",
      " 0.99607843 0.88235294 0.99607843 0.99607843 0.99607843 0.98039216\n",
      " 0.89803922 0.99607843 0.99607843 0.54901961 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06666667 0.25882353 0.05490196\n",
      " 0.2627451  0.2627451  0.2627451  0.23137255 0.08235294 0.9254902\n",
      " 0.99607843 0.41568627 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3254902  0.99215686 0.81960784 0.07058824\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.08627451\n",
      " 0.91372549 1.         0.3254902  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.50588235 0.99607843 0.93333333\n",
      " 0.17254902 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.23137255 0.97647059 0.99607843 0.24313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.52156863 0.99607843\n",
      " 0.73333333 0.01960784 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.03529412 0.80392157 0.97254902 0.22745098 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.49411765\n",
      " 0.99607843 0.71372549 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.29411765 0.98431373 0.94117647 0.22352941\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.0745098\n",
      " 0.86666667 0.99607843 0.65098039 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.79607843 0.99607843 0.85882353\n",
      " 0.1372549  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.14901961 0.99607843 0.99607843 0.30196078 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.12156863 0.87843137 0.99607843\n",
      " 0.45098039 0.00392157 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.52156863 0.99607843 0.99607843 0.20392157 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.23921569 0.94901961\n",
      " 0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.4745098  0.99607843 0.99607843 0.85882353\n",
      " 0.15686275 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4745098  0.99607843 0.81176471 0.07058824 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Insoection of one vector\n",
    "print(training_images[0])\n",
    "print(test_images[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:09:03.088271Z",
     "start_time": "2025-01-15T17:09:03.076385Z"
    }
   },
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Distances and Similarity computation**"
   ],
   "metadata": {
    "id": "wgDZyqy4R83o"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to compute the euclidean distance between the values of two vectors I have to apply the previouds formula to each pair of vector i,j"
   ],
   "metadata": {
    "id": "cJGVNck9UfB4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Library Euclidean distance\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Number of images of training and test\n",
    "train_images = training_images  # 60,000 training_imges\n",
    "test_images = test_images  # 10,000 test images\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 1000\n",
    "\n",
    "# Preallocate distance matrix for test images vs train images\n",
    "distance_matrix = np.zeros((test_images.shape[0], train_images.shape[0]))\n",
    "\n",
    "# Compute distances batch-wise\n",
    "for i in range(0, test_images.shape[0], batch_size):  # Loop over test images in batches\n",
    "    end_i = min(i + batch_size, test_images.shape[0])  # Batch limit for test images\n",
    "    print(f\"Computing distances for test images batch {i}:{end_i}\")\n",
    "    # Compute distances for the current test batch against all train images\n",
    "    distance_matrix[i:end_i] = euclidean_distances(test_images[i:end_i], train_images)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "e5_IFaojR7WV",
    "outputId": "11aa921d-ca64-4391-a1bc-69ce1ce74b54",
    "ExecuteTime": {
     "end_time": "2025-01-15T17:09:18.338035Z",
     "start_time": "2025-01-15T17:09:10.702148Z"
    }
   },
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing distances for test images batch 0:1000\n",
      "Computing distances for test images batch 1000:2000\n",
      "Computing distances for test images batch 2000:3000\n",
      "Computing distances for test images batch 3000:4000\n",
      "Computing distances for test images batch 4000:5000\n",
      "Computing distances for test images batch 5000:6000\n",
      "Computing distances for test images batch 6000:7000\n",
      "Computing distances for test images batch 7000:8000\n",
      "Computing distances for test images batch 8000:9000\n",
      "Computing distances for test images batch 9000:10000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.39527723 10.39462864  9.4404245  10.02592027  9.19689866]\n",
      " [11.18299431 11.45103747 11.65692261 10.84743098 11.53665505]\n",
      " [ 9.22376617 10.07628267  9.15318312  6.55862628  9.00101835]\n",
      " [10.03145763  7.76738813 11.85379017 12.15051004 10.62868526]\n",
      " [10.59288206 10.9646049   7.72982659  9.96961011  9.69742075]]\n"
     ]
    }
   ],
   "source": [
    "print(distance_matrix[:5, :5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T14:44:44.544847Z",
     "start_time": "2025-01-15T14:44:44.539728Z"
    }
   },
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "# Euclidean distance by my own\n",
    "# Function to calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(v1, v2):\n",
    "    diff = v1 - v2  # Subtract element by element\n",
    "    return np.sqrt(np.sum(diff ** 2))  # Square the differences, sum, and take sqrt\n",
    "\n",
    "# Function to compute the distance matrix between two datasets (test vs training)\n",
    "def compute_distance_matrix_batches(test_data, train_data, batch_size=1000):\n",
    "    n_test = len(test_data)  # Number of test vectors\n",
    "    n_train = len(train_data)  # Number of training vectors\n",
    "    distance_matrix_2 = np.zeros((n_test, n_train))  # Preallocate the result matrix\n",
    "\n",
    "    for i in range(0, n_test, batch_size):  # Process test data in batches\n",
    "        end_i = min(i + batch_size, n_test)  # Ensure batch doesn't exceed bounds\n",
    "        print(f\"Processing batch {i}:{end_i} of test data\")\n",
    "        \n",
    "        for j in range(n_train):  # Compare each test vector in the batch to all training vectors\n",
    "            for k in range(i, end_i):  # Iterate over the current batch\n",
    "                distance_matrix_2[k, j] = euclidean_distance(test_data[k], train_data[j])  # Compute distance\n",
    "    return distance_matrix_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "BW-vAq4AZDat",
    "ExecuteTime": {
     "end_time": "2025-01-15T14:44:58.960449Z",
     "start_time": "2025-01-15T14:44:58.953116Z"
    }
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0:1000 of test data\n",
      "Processing batch 1000:2000 of test data\n",
      "Processing batch 2000:3000 of test data\n",
      "Processing batch 3000:4000 of test data\n",
      "Processing batch 4000:5000 of test data\n",
      "Processing batch 5000:6000 of test data\n",
      "Processing batch 6000:7000 of test data\n",
      "Processing batch 7000:8000 of test data\n",
      "Processing batch 8000:9000 of test data\n",
      "Processing batch 9000:10000 of test data\n",
      "(10000, 60000)\n"
     ]
    }
   ],
   "source": [
    "#Calling my own functions\n",
    "# Calculate the distance matrix for all test images against all training images\n",
    "distance_matrix_euclidean_2 = compute_distance_matrix_batches(test_images, training_images, batch_size=1000)\n",
    "\n",
    "# checking dimensions\n",
    "print(distance_matrix_euclidean_2.shape)  # Expected: (10000, 60000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T15:10:12.660352Z",
     "start_time": "2025-01-15T14:45:29.072372Z"
    }
   },
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.39527723 10.39462864  9.4404245  10.02592027  9.19689866]\n",
      " [11.18299431 11.45103747 11.65692261 10.84743098 11.53665505]\n",
      " [ 9.22376617 10.07628267  9.15318312  6.55862628  9.00101835]\n",
      " [10.03145763  7.76738813 11.85379017 12.15051004 10.62868526]\n",
      " [10.59288206 10.9646049   7.72982659  9.96961011  9.69742075]]\n"
     ]
    }
   ],
   "source": [
    "print(distance_matrix_euclidean_2[:5, :5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T15:11:06.374100Z",
     "start_time": "2025-01-15T15:11:06.366350Z"
    }
   },
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "COSINE SIMILARITY "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0:1000 of test images\n",
      "Processing batch 1000:2000 of test images\n",
      "Processing batch 2000:3000 of test images\n",
      "Processing batch 3000:4000 of test images\n",
      "Processing batch 4000:5000 of test images\n",
      "Processing batch 5000:6000 of test images\n",
      "Processing batch 6000:7000 of test images\n",
      "Processing batch 7000:8000 of test images\n",
      "Processing batch 8000:9000 of test images\n",
      "Processing batch 9000:10000 of test images\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity with library\n",
    "# Splitting the test images in batches with size 1000\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Batch size\n",
    "batch_size = 1000 #test images per batch\n",
    "\n",
    "#Training and test images quantity\n",
    "n_test = test_images.shape[0] #10000\n",
    "n_train = training_images.shape[0] #60000\n",
    "\n",
    "# Preallocate the result matrix for cosine similarity\n",
    "cosine_similarity_matrix = np.zeros((n_test, n_train))\n",
    "\n",
    "#Process test images in batches\n",
    "for i in range(0, n_test, batch_size):\n",
    "    end_i = min(i + batch_size, n_test)  # Ensure batch doesn't exceed bounds\n",
    "    print(f\"Processing batch {i}:{end_i} of test images\")\n",
    "\n",
    "    # Current batch of test images\n",
    "    test_batch = test_images[i:end_i]\n",
    "\n",
    "    # Compute norms for test batch and training images\n",
    "    test_norms = norm(test_batch, axis=1).reshape(-1, 1)  # Norms for test images\n",
    "    train_norms = norm(training_images, axis=1).reshape(1, -1)  # Norms for training images\n",
    "\n",
    "    # Compute dot products between test batch and all training images\n",
    "    dot_products = np.dot(test_batch, training_images.T)\n",
    "\n",
    "    # Compute cosine similarity for the batch\n",
    "    cosine_similarity_matrix[i:end_i] = dot_products / (test_norms * train_norms)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T15:27:49.497231Z",
     "start_time": "2025-01-15T15:27:41.317602Z"
    }
   },
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42334021 0.35044986 0.24752037 0.14505682 0.38339982]\n",
      " [0.33678871 0.3477641  0.13543288 0.25160656 0.23853338]\n",
      " [0.34908289 0.29210832 0.0725565  0.54422919 0.27659917]\n",
      " [0.55345092 0.74640531 0.27690166 0.23308376 0.46985732]\n",
      " [0.26991794 0.2810965  0.50422782 0.1692757  0.32314815]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity_matrix[:5, :5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T15:28:06.292314Z",
     "start_time": "2025-01-15T15:28:06.281440Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNN IMPLEMENTATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#KNN function \n",
    "def KNN(matrix, training_labels, k, test_index=None):\n",
    "    predictions = []  # To store the predicted labels\n",
    "\n",
    "    if test_index is not None:  # Check if a specific test index is provided\n",
    "        # Sort distances for the specific test point\n",
    "        distances_sorted = np.argsort(matrix[test_index])[:k]\n",
    "        k_nearest_labels = training_labels[distances_sorted]\n",
    "        predicted_label = np.bincount(k_nearest_labels).argmax()\n",
    "        return predicted_label  # Return prediction for the specific test point\n",
    "\n",
    "    # If no test index is provided, predict for all test points\n",
    "    for i in range(len(matrix)):\n",
    "        distances_sorted = np.argsort(matrix[i])[:k]\n",
    "        k_nearest_labels = training_labels[distances_sorted]\n",
    "        predicted_label = np.bincount(k_nearest_labels).argmax()\n",
    "        predictions.append(predicted_label)\n",
    "\n",
    "    return predictions  # Return predictions for all test points\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:06:12.213408Z",
     "start_time": "2025-01-15T17:06:12.209185Z"
    }
   },
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label for test point: 2\n"
     ]
    }
   ],
   "source": [
    "predicted_label = KNN (distance_matrix, training_labels, k=20, test_index=1)\n",
    "print(f\"Predicted label for test point: {predicted_label}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:19:18.479671Z",
     "start_time": "2025-01-15T17:19:18.471639Z"
    }
   },
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label for test point 1: 2\n"
     ]
    }
   ],
   "source": [
    "#Checking the test point with index 1\n",
    "print(f\"True label for test point 1: {test_labels[1]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:31:56.549148Z",
     "start_time": "2025-01-15T17:31:56.527211Z"
    }
   },
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\r\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/42/2a/6d66d0fba41e13e9ca6512a0a51170f43e7e7ed3a8dfa036324100775612/matplotlib-3.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading matplotlib-3.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\r\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/6b/6a/7833cfae2c1e63d1d8875a50fd23371394f540ce809d7383550681a1fa64/contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib)\r\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\r\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\r\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/89/58/fbcf5dff7e3ea844bb00c4d806ca1e339e1f2dce5529633bf4842c0c9a1f/fonttools-4.55.3-cp312-cp312-macosx_10_13_universal2.whl.metadata\r\n",
      "  Downloading fonttools-4.55.3-cp312-cp312-macosx_10_13_universal2.whl.metadata (165 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m165.1/165.1 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\r\n",
      "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/60/26/d6a0db6785dd35d3ba5bf2b2df0aedc5af089962c6eb2cbf67a15b81369e/kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.2.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (24.2)\r\n",
      "Collecting pillow>=8 (from matplotlib)\r\n",
      "  Obtaining dependency information for pillow>=8 from https://files.pythonhosted.org/packages/b9/d8/f6004d98579a2596c098d1e30d10b248798cceff82d2b77aa914875bfea1/pillow-11.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading pillow-11.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.1 kB)\r\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\r\n",
      "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/1c/a7/c8a2d361bf89c0d9577c934ebb7421b25dc84bf3a8e3ac0a40aed9acc547/pyparsing-3.2.1-py3-none-any.whl.metadata\r\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "Downloading matplotlib-3.10.0-cp312-cp312-macosx_11_0_arm64.whl (8.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.0/8.0 MB\u001B[0m \u001B[31m10.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl (255 kB)\r\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Downloading fonttools-4.55.3-cp312-cp312-macosx_10_13_universal2.whl (2.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m10.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl (65 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m65.1/65.1 kB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pillow-11.1.0-cp312-cp312-macosx_11_0_arm64.whl (3.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m10.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m107.7/107.7 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\r\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:14:01.639062Z",
     "start_time": "2025-01-15T17:13:44.099665Z"
    }
   },
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_data, cmap='gray')  \n",
    "plt.title(f\"True Label: {test_labels[test_point_index]} - Predicted: {2}\")\n",
    "plt.axis('off') \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:19:47.119654Z",
     "start_time": "2025-01-15T17:19:47.069980Z"
    }
   },
   "execution_count": 74
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predicting for all datapoints in test data and saving that information"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predicted_label = KNN (distance_matrix, training_labels, k=3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:24:23.156397Z",
     "start_time": "2025-01-15T17:23:39.816428Z"
    }
   },
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.05%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(predicted_label == test_labels) * 100  \n",
    "print(f\"Accuracy: {accuracy}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-15T17:27:29.090865Z",
     "start_time": "2025-01-15T17:27:29.081497Z"
    }
   },
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
